{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gutenberg_book(\n",
    "\tid: int|None = 84,\n",
    "\tdata_temp: Path|str = \"../data/gutenberg_data\",\n",
    "\tremove_gutenberg_meta: bool = True,\n",
    ") -> str:\n",
    "\t\n",
    "\tdata_temp = Path(data_temp)\n",
    "\tdata_temp.mkdir(parents=True, exist_ok=True)\n",
    "\t\n",
    "\turl: str = f\"https://www.gutenberg.org/cache/epub/{id}/pg{id}.txt\"\n",
    "\tdata_path: Path = Path(data_temp) / f\"{id}.txt\"\n",
    "\tdata: str\n",
    "\t# read from cache if it exists\n",
    "\tif data_path.exists():\n",
    "\t\twith open(data_path, 'r', encoding='utf-8') as file:\n",
    "\t\t\tdata = file.read()\n",
    "\telse:\n",
    "\t\t# download if it doesn't exist\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\tresponse.raise_for_status()  # Ensure that the download was successful\n",
    "\t\tdata = response.text\n",
    "\n",
    "\t\t# save to cache\n",
    "\t\twith open(data_path, 'w', encoding='utf-8') as file:\n",
    "\t\t\tfile.write(data)\n",
    "\n",
    "\t# remove header/footer\n",
    "\tif remove_gutenberg_meta:\n",
    "\t\tdata = '***'.join(data.split('***')[2:])\n",
    "\t\tdata = '***'.join(data.split('***')[:-1])\n",
    "\t\n",
    "\treturn data\n",
    "\n",
    "def get_many_books(\n",
    "\t\tids: list[int],\n",
    "\t\tdata_temp: Path|str = \"../data/gutenberg_data\",\n",
    "\t) -> list[str]:\n",
    "\t\n",
    "\tdata: list[str] = []\n",
    "\tfor id in ids:\n",
    "\t\tprint(f\"Getting book {id}...\")\n",
    "\t\titem: str = get_gutenberg_book(id, data_temp)\n",
    "\t\tprint(f\"\\t{len(item)} characters read\")\n",
    "\t\tdata.append(item)\n",
    "\t\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(\n",
    "\ttext: str,\n",
    "\tallowed_punctuation: str = \"-.,;:!?()\\\"\" + \"\".join(str(x) for x in range(10)),\n",
    "\tpunctuation_convert: dict[str,str] = {'â€”': '-'},\n",
    "\tnumbers_allowed: bool = True,\n",
    ") -> str:\n",
    "\t\n",
    "\t# replace some special characters which unicode won't normalize properly\n",
    "\tfor char, replacement in punctuation_convert.items():\n",
    "\t\ttext = text.replace(char, replacement)\n",
    "\n",
    "\t# if a line has \".jpg\" in it, remove that line (this is specific to Don Quixote)\n",
    "\ttext = '\\n'.join(\n",
    "\t\tline \n",
    "\t\tfor line in text.split('\\n')\n",
    "\t\tif '.jpg' not in line\n",
    "\t)\n",
    "\n",
    "\t# Normalize the string to decompose Unicode characters\n",
    "\ttext = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "\t# Encode to ASCII bytes, then decode back to string, ignoring errors\n",
    "\ttext = text.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "\t# remove newlines and tabs\n",
    "\ttext = text.replace('\\n', ' ').replace('\\t', ' ')\n",
    "\n",
    "\n",
    "\t# put spaces around allowed punctuation\n",
    "\tfor char in allowed_punctuation:\n",
    "\t\ttext = text.replace(char, f' {char} ')\n",
    "\n",
    "\n",
    "\t# remove leading and trailing spaces\n",
    "\ttext = text.strip()\n",
    "\n",
    "\t# remove multiple spaces\n",
    "\twhile '  ' in text:\n",
    "\t\ttext = text.replace('  ', ' ')\n",
    "\n",
    "\n",
    "\t# remove all characters except (alphanumeric, allowed_punctuation, ' ')\n",
    "\ttext = ''.join(\n",
    "\t\t(\n",
    "\t\t\tchar \n",
    "\t\t\tif (\n",
    "\t\t\t\t(char.isalnum() and numbers_allowed) or (char.isalpha)\n",
    "\t\t\t\tor char in allowed_punctuation \n",
    "\t\t\t\tor char == ' '\n",
    "\t\t\t)\n",
    "\t\t\telse ' '\n",
    "\t\t)\n",
    "\t\tfor char in text \n",
    "\t)\n",
    "\n",
    "\t# convert to lowercase\n",
    "\ttext = text.lower()\n",
    "\n",
    "\ttext = text.strip()\n",
    "\n",
    "\treturn text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(\n",
    "\ttext: str,\n",
    "\tprocess: bool = False,\n",
    ") -> list[str]:\n",
    "\tif process:\n",
    "\t\ttext = process_text(text)\n",
    "\treturn text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting book 84...\n",
      "\t426785 characters read\n",
      "Getting book 15...\n",
      "\t1241025 characters read\n",
      "Getting book 18...\n",
      "\t1192776 characters read\n",
      "Getting book 82...\n",
      "\t1124986 characters read\n",
      "Getting book 996...\n",
      "\t2342262 characters read\n",
      "Getting book 2600...\n",
      "\t3273998 characters read\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_RAW: list[str] = get_many_books([84, 15, 18, 82, 996, 2600])\n",
    "DATA: str = \" \".join(process_text(x, allowed_punctuation=\"\", numbers_allowed=False) for x in DATA_RAW)\n",
    "\n",
    "#print(DATA[:1000])\n",
    "\n",
    "DATA_TOKENIZED: list[str] = tokenize(DATA)\n",
    "TOKEN_SET: set[str] = set(DATA_TOKENIZED)\n",
    "TOKEN_ALPHABET: list[str] = sorted(list(TOKEN_SET))\n",
    "TOKEN_TO_INDEX: dict[str, int] = {token: i for i, token in enumerate(TOKEN_ALPHABET)}\n",
    "#INDEX_TO_TOKEN: dict[int, str] = {i: token for i, token in enumerate(TOKEN_ALPHABET)}\n",
    "MODEL_DATA: list[int] = [TOKEN_TO_INDEX[token] for token in DATA_TOKENIZED]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frankenstein;', 'or,', 'the', 'modern', 'prometheus', 'by', 'mary', 'wollstonecraft', '(godwin)', 'shelley', 'contents', 'letter', '1', 'letter', '2', 'letter', '3', 'letter', '4', 'chapter', '1', 'chapter', '2', 'chapter', '3', 'chapter', '4', 'chapter', '5', 'chapter', '6', 'chapter', '7', 'chapter', '8', 'chapter', '9', 'chapter', '10', 'chapter', '11', 'chapter', '12', 'chapter', '13', 'chapter', '14', 'chapter', '15', 'chapter', '16', 'chapter', '17', 'chapter', '18', 'chapter', '19', 'chapter', '20', 'chapter', '21', 'chapter', '22', 'chapter', '23', 'chapter', '24', 'letter', '1', '_to', 'mrs.', 'saville,', 'england._', 'st.', 'petersburgh,', 'dec.', '11th,', '17-.', 'you', 'will', 'rejoice', 'to', 'hear', 'that', 'no', 'disaster', 'has', 'accompanied', 'the', 'commencement', 'of', 'an', 'enterprise', 'which', 'you', 'have', 'regarded', 'with', 'such', 'evil', 'forebodings.', 'i', 'arrived', 'here', 'yesterday,', 'and', 'my', 'first', 'task', 'is', 'to', 'assure', 'my', 'dear', 'sister', 'of', 'my', 'welfare', 'and', 'increasing', 'confidence', 'in', 'the', 'success', 'of', 'my', 'undertaking.', 'i', 'am', 'already', 'far', 'north', 'of', 'london,', 'and', 'as', 'i', 'walk', 'in', 'the', 'streets', 'of', 'petersburgh,', 'i', 'feel', 'a', 'cold', 'northern', 'breeze', 'play', 'upon', 'my', 'cheeks,', 'which', 'braces', 'my', 'nerves', 'and', 'fills', 'me', 'with', 'delight.', 'do', 'you', 'understand', 'this', 'feeling?', 'this', 'breeze,', 'which', 'has', 'travelled', 'from', 'the', 'regions', 'towards', 'which', 'i', 'am', 'advancing,', 'gives', 'me', 'a', 'foretaste', 'of', 'those', 'icy', 'climes.', 'inspirited', 'by', 'this', 'wind', 'of', 'promise,', 'my', 'daydreams', 'become', 'more', 'fervent', 'and', 'vivid.', 'i', 'try', 'in', 'vain', 'to', 'be', 'persuaded', 'that', 'the', 'pole', 'is', 'the', 'seat', 'of', 'frost', 'and', 'desolation;', 'it', 'ever', 'presents', 'itself', 'to', 'my', 'imagination', 'as', 'the', 'region', 'of', 'beauty', 'and', 'delight.', 'there,', 'margaret,', 'the', 'sun', 'is', 'for', 'ever', 'visible,', 'its', 'broad', 'disk', 'just', 'skirting', 'the', 'horizon', 'and', 'diffusing', 'a', 'perpetual', 'splendour.', 'there-for', 'with', 'your', 'leave,', 'my', 'sister,', 'i', 'will', 'put', 'some', 'trust', 'in', 'preceding', 'navigators-there', 'snow', 'and', 'frost', 'are', 'banished;', 'and,', 'sailing', 'over', 'a', 'calm', 'sea,', 'we', 'may', 'be', 'wafted', 'to', 'a', 'land', 'surpassing', 'in', 'wonders', 'and', 'in', 'beauty', 'every', 'region', 'hitherto', 'discovered', 'on', 'the', 'habitable', 'globe.', 'its', 'productions', 'and', 'features', 'may', 'be', 'without', 'example,', 'as', 'the', 'phenomena', 'of', 'the', 'heavenly', 'bodies', 'undoubtedly', 'are', 'in', 'those', 'undiscovered', 'solitudes.', 'what', 'may', 'not', 'be', 'expected', 'in', 'a', 'country', 'of', 'eternal', 'light?', 'i', 'may', 'there', 'discover', 'the', 'wondrous', 'power', 'which', 'attracts', 'the', 'needle', 'and', 'may', 'regulate', 'a', 'thousand', 'celestial', 'observations', 'that', 'require', 'only', 'this', 'voyage', 'to', 'render', 'their', 'seeming', 'eccentricities', 'consistent', 'for', 'ever.', 'i', 'shall', 'satiate', 'my', 'ardent', 'curiosity', 'with', 'the', 'sight', 'of', 'a', 'part', 'of', 'the', 'world', 'never', 'before', 'visited,', 'and', 'may', 'tread', 'a', 'land', 'never', 'before', 'imprinted', 'by', 'the', 'foot', 'of', 'man.', 'these', 'are', 'my', 'enticements,', 'and', 'they', 'are', 'sufficient', 'to', 'conquer', 'all', 'fear', 'of', 'danger', 'or', 'death', 'and', 'to', 'induce', 'me', 'to', 'commence', 'this', 'laborious', 'voyage', 'with', 'the', 'joy', 'a', 'child', 'feels', 'when', 'he', 'embarks', 'in', 'a', 'little', 'boat,', 'with', 'his', 'holiday', 'mates,', 'on', 'an', 'expedition', 'of', 'discovery', 'up', 'his', 'native', 'river.', 'but', 'supposing', 'all', 'these', 'conjectures', 'to', 'be', 'false,', 'you', 'cannot', 'contest', 'the', 'inestimable', 'benefit', 'which', 'i', 'shall', 'confer', 'on', 'all', 'mankind,', 'to', 'the', 'last', 'generation,', 'by', 'discovering', 'a', 'passage', 'near', 'the', 'pole', 'to', 'those', 'countries,', 'to', 'reach', 'which', 'at', 'present', 'so', 'many', 'months', 'are', 'requisite;', 'or', 'by', 'ascertaining', 'the', 'secret', 'of', 'the', 'magnet,', 'which,', 'if', 'at', 'all', 'possible,', 'can', 'only', 'be', 'effected', 'by', 'an', 'undertaking', 'such', 'as', 'mine.', 'these', 'reflections', 'have', 'dispelled', 'the', 'agitation', 'with', 'which', 'i', 'began', 'my', 'letter,', 'and', 'i', 'feel', 'my', 'heart', 'glow', 'with', 'an', 'enthusiasm', 'which', 'elevates', 'me', 'to', 'heaven,', 'for', 'nothing', 'contributes', 'so', 'much', 'to', 'tranquillise', 'the', 'mind', 'as', 'a', 'steady', 'purpose-a', 'point', 'on', 'which', 'the', 'soul', 'may', 'fix', 'its', 'intellectual', 'eye.', 'this', 'expedition', 'has', 'been', 'the', 'favourite', 'dream', 'of', 'my', 'early', 'years.', 'i', 'have', 'read', 'with', 'ardour', 'the', 'accounts', 'of', 'the', 'various', 'voyages', 'which', 'have', 'been', 'made', 'in', 'the', 'prospect', 'of', 'arriving', 'at', 'the', 'north', 'pacific', 'ocean', 'through', 'the', 'seas', 'which', 'surround', 'the', 'pole.', 'you', 'may', 'remember', 'that', 'a', 'history', 'of', 'all', 'the', 'voyages', 'made', 'for', 'purposes', 'of', 'discovery', 'composed', 'the', 'whole', 'of', 'our', 'good', 'uncle', 'thomas', 'library.', 'my', 'education', 'was', 'neglected,', 'yet', 'i', 'was', 'passionately', 'fond', 'of', 'reading.', 'these', 'volumes', 'were', 'my', 'study', 'day', 'and', 'night,', 'and', 'my', 'familiarity', 'with', 'them', 'increased', 'that', 'regret', 'which', 'i', 'had', 'felt,', 'as', 'a', 'child,', 'on', 'learning', 'that', 'my', 'fathers', 'dying', 'injunction', 'had', 'forbidden', 'my', 'uncle', 'to', 'allow', 'me', 'to', 'embark', 'in', 'a', 'seafaring', 'life.', 'these', 'visions', 'faded', 'when', 'i', 'perused,', 'for', 'the', 'first', 'time,', 'those', 'poets', 'whose', 'effusions', 'entranced', 'my', 'soul', 'and', 'lifted', 'it', 'to', 'heaven.', 'i', 'also', 'became', 'a', 'poet', 'and', 'for', 'one', 'year', 'lived', 'in', 'a', 'paradise', 'of', 'my', 'own', 'creation;', 'i', 'imagined', 'that', 'i', 'also', 'might', 'obtain', 'a', 'niche', 'in', 'the', 'temple', 'where', 'the', 'names', 'of', 'homer', 'and', 'shakespeare', 'are', 'consecrated.', 'you', 'are', 'well', 'acquainted', 'with', 'my', 'failure', 'and', 'how', 'heavily', 'i', 'bore', 'the', 'disappointment.', 'but', 'just', 'at', 'that', 'time', 'i', 'inherited', 'the', 'fortune', 'of', 'my', 'cousin,', 'and', 'my', 'thoughts', 'were', 'turned', 'into', 'the', 'channel', 'of', 'their', 'earlier', 'bent.', 'six', 'years', 'have', 'passed', 'since', 'i', 'resolved', 'on', 'my', 'present', 'undertaking.', 'i', 'can,', 'even', 'now,', 'remember', 'the', 'hour', 'from', 'which', 'i', 'dedicated', 'myself', 'to', 'this', 'great', 'enterprise.', 'i', 'commenced', 'by', 'inuring', 'my', 'body', 'to', 'hardship.', 'i', 'accompanied', 'the', 'whale-fishers', 'on', 'several', 'expeditions', 'to', 'the', 'north', 'sea;', 'i', 'voluntarily', 'endured', 'cold,', 'famine,', 'thirst,', 'and', 'want', 'of', 'sleep;', 'i', 'often', 'worked', 'harder', 'than', 'the', 'common', 'sailors', 'during', 'the', 'day', 'and', 'devoted', 'my', 'nights', 'to', 'the', 'study', 'of', 'mathematics,', 'the', 'theory', 'of', 'medicine,', 'and', 'those', 'branches', 'of', 'physical', 'science', 'from', 'which', 'a', 'naval', 'adventurer', 'might', 'derive', 'the', 'greatest', 'practical', 'advantage.', 'twice', 'i', 'actually', 'hired', 'myself', 'as', 'an', 'under-mate', 'in', 'a', 'greenland', 'whaler,', 'and', 'acquitted', 'myself', 'to', 'admiration.', 'i', 'must', 'own', 'i', 'felt', 'a', 'little', 'proud', 'when', 'my', 'captain', 'offered', 'me', 'the', 'second', 'dignity', 'in', 'the', 'vessel', 'and', 'entreated', 'me', 'to', 'remain', 'with', 'the', 'greatest', 'earnestness,', 'so', 'valuable', 'did', 'he', 'consider', 'my', 'services.', 'and', 'now,', 'dear', 'margaret,', 'do', 'i', 'not', 'deserve', 'to', 'accomplish', 'some', 'great', 'purpose?', 'my', 'life', 'might', 'have', 'been', 'passed', 'in', 'ease', 'and', 'luxury,', 'but', 'i', 'preferred', 'glory', 'to', 'every', 'enticement', 'that', 'wealth', 'placed', 'in', 'my', 'path.', 'oh,', 'that', 'some', 'encouraging', 'voice', 'would', 'answer', 'in', 'the', 'affirmative!', 'my', 'courage', 'and', 'my', 'resolution', 'is', 'firm;', 'but', 'my', 'hopes', 'fluctuate,', 'and', 'my', 'spirits', 'are', 'often', 'depressed.', 'i', 'am', 'about', 'to', 'proceed', 'on', 'a', 'long', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(DATA_TOKENIZED[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
